# Credits Brasil Data Warehouse (Credits DW)

Este projeto implementa um pipeline de dados (ETL) containerizado para ingerir dados brutos de arquivos (CSV, Excel, ODS) em um Data Warehouse PostgreSQL na camada Bronze (Raw).

## üìã Vis√£o Geral

O pipeline √© desenvolvido em Python e orquestrado via Docker Compose. Ele suporta:
- **Ingest√£o Din√¢mica:** Detecta automaticamente arquivos de `faturamento`, `base_oficial` e `usuarios` no diret√≥rio de input.
- **Valida√ß√£o de Schema:** Verifica se os arquivos de entrada correspondem aos templates esperados.
- **Limpeza de Dados:** Tratamento b√°sico de tipos num√©ricos e datas.
- **Auditoria Robusta:** Hist√≥rico de execu√ß√µes e logs de rejei√ß√£o (`auditoria.historico_execucao` e `auditoria.log_rejeicao`) no banco de dados.
- **Rastreamento de Usu√°rio:** Identifica automaticamente quem executou cada processo via `DB_USER` do .env.
- **Estrat√©gia "Warn-on-Fail":** Registros com campos obrigat√≥rios vazios s√£o ingeridos com um aviso (WARN), enquanto erros cr√≠ticos de dados rejeitam o registro (ERROR).

## üèóÔ∏è Estrutura do Projeto

```
credits-dw/
‚îú‚îÄ‚îÄ docker/
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ input/       # Coloque seus arquivos CSV/XLSX aqui
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ processed/   # Arquivos processados s√£o movidos para c√°
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ templates/   # Templates para valida√ß√£o de cabe√ßalho
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îî‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ python/
‚îÇ   ‚îú‚îÄ‚îÄ core/            # L√≥gica base (Ingestor, Validador, Cleaner)
‚îÇ   ‚îú‚îÄ‚îÄ ingestors/       # Classes espec√≠ficas para cada tipo de arquivo
‚îÇ   ‚îú‚îÄ‚îÄ scripts/         # Scripts execut√°veis (run_pipeline.py, etc)
‚îÇ   ‚îî‚îÄ‚îÄ utils/           # Utilit√°rios (DB, Audit, Logger)
‚îú‚îÄ‚îÄ QUERIES.md           # Exemplos de consultas SQL
‚îú‚îÄ‚îÄ run_pipeline.sh      # Script facilitador para rodar o ETL
‚îú‚îÄ‚îÄ reset_env.sh         # Script para limpar dados e resetar tabelas
‚îî‚îÄ‚îÄ requirements.txt
```

## üöÄ Como Executar

### Pr√©-requisitos
- Docker e Docker Compose instalados.
- Arquivo `.env` configurado (copie de `.env.example`).

### 1. Configurar Vari√°veis de Ambiente
Crie um arquivo `.env` na raiz do projeto com as credenciais do banco:
```bash
cp .env.example .env
# Edite o .env com suas configura√ß√µes
```

### 2. Colocar Arquivos de Input
Mova os arquivos que deseja processar para `docker/data/input/`.
Exemplo:
```bash
cp meus_dados/*.csv docker/data/input/
```

### 3. Rodar o Pipeline
Execute o script wrapper:
```bash
./run_pipeline.sh
```
Isso ir√°:
1. Buildar a imagem Docker.
2. Executar o processamento.
3. Mover os arquivos processados para `docker/data/processed/YYYY/MM/DD/`.
4. Registrar o resultado no banco de dados.

### 4. Verificar Resultados
Consulte o arquivo [QUERIES.md](QUERIES.md) para exemplos de como explorar os dados ingeridos.

Para verificar erros ou avisos de ingest√£o:
```sql
SELECT * FROM auditoria.log_rejeicao ORDER BY data_hora DESC LIMIT 100;
```

## üõ†Ô∏è Comandos √öteis

- **Resetar Ambiente:** Limpa tabelas bronze e arquivos processados (CUIDADO!).
  ```bash
  ./reset_env.sh
  ```

## üìù Decis√µes de Arquitetura

- **Camada Bronze (Raw):** O foco √© ingerir os dados com m√≠nima transforma√ß√£o destrutiva.
- **Valida√ß√£o Flex√≠vel:** Campos obrigat√≥rios ausentes geram alertas (`WARN`) mas n√£o bloqueiam a ingest√£o, permitindo corre√ß√£o posterior na camada Silver.
- **Alta Performance:** Uso de `COPY FROM STDIN` do PostgreSQL para carga em massa.

## üîç Campos Obrigat√≥rios por Ingestor

### Faturamento
Apenas 5 campos essenciais:
- `numero_documento`: Identificador √∫nico do documento
- `cnpj`: Cliente (essencial para joins)
- `data_fat`: Data de faturamento 
- `valor_da_conta`: Valor principal
- `empresa`: Empresa emissora (multi-tenant)

> **Nota**: Reduzido de 33 para 5 campos obrigat√≥rios seguindo princ√≠pios da camada Bronze. Valida√ß√µes de neg√≥cio mais rigorosas devem ser feitas na Silver.

### Base Oficial
14 campos refletindo estrutura organizacional:
- `cnpj`, `status`, `manter_no_baseline`
- `razao_social`, `nome_fantasia`
- `canal_1`, `canal_2`
- `lider`, `responsavel`
- `empresa`, `grupo`, `corte`, `segmento`, `obs`

### Usu√°rios
Todos os campos do template s√£o obrigat√≥rios para manter integridade da hierarquia de vendas, exceto `acesso_indireto` e `acesso_temporario` que s√£o opcionais.

## üöÄ Otimiza√ß√µes de Performance

### √çndices do Banco de Dados

O projeto inclui √≠ndices otimizados para queries anal√≠ticas comuns. Veja o arquivo [INDEXES.md](INDEXES.md) para:
- Lista completa de √≠ndices criados
- Scripts SQL para aplicar
- Instru√ß√µes de monitoramento

**Principais √≠ndices:**
- `bronze.faturamento`: √çndices compostos por empresa+vendedor, cnpj+data
- `bronze.base_oficial`: √çndices por empresa+grupo, canais
- `auditoria.log_rejeicao`: √çndices para debugging (execu√ß√£o, severidade, tabela)

### Estrat√©gia de Valida√ß√£o (WARN vs ERROR)

- **WARN**: Campos obrigat√≥rios vazios ‚Üí Dados s√£o inseridos, mas registrado warning
- **ERROR**: Tipos inv√°lidos (ex: texto em campo num√©rico) ‚Üí Linha rejeitada completamente

Isso permite m√°xima ingest√£o de dados na Bronze, com corre√ß√£o posterior na Silver.

## üîß Troubleshooting

### Problema: Muitos warnings de campos obrigat√≥rios
**Solu√ß√£o**: Revise a qualidade dos dados de origem. Warnings n√£o bloqueiam ingest√£o.

```sql
-- Ver campos mais problem√°ticos
SELECT campo_falha, COUNT(*) as total
FROM auditoria.log_rejeicao
WHERE severidade = 'WARN'
GROUP BY campo_falha
ORDER BY total DESC
LIMIT 10;
```

### Problema: Arquivo n√£o est√° sendo processado
**Causas comuns:**
1. Nome do arquivo n√£o corresponde ao padr√£o esperado
2. Arquivo duplicado (mesmo hash MD5)
3. Headers n√£o correspondem ao template

```sql
-- Ver √∫ltimas execu√ß√µes com erro
SELECT script_nome, tabela_destino, mensagem_erro, data_inicio
FROM auditoria.historico_execucao
WHERE status = 'erro'
ORDER BY data_inicio DESC
LIMIT 5;
```

### Problema: Performance lenta
**Solu√ß√µes:**
1. Verifique se √≠ndices foram criados (veja INDEXES.md)
2. Execute `VACUUM ANALYZE` ap√≥s grandes cargas
3. Considere aumentar `work_mem` do PostgreSQL para sorts grandes

```sql
-- Verificar tamanho das tabelas
SELECT 
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size
FROM pg_tables
WHERE schemaname IN ('bronze', 'auditoria')
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;
```

### Problema: Erro de conex√£o com o banco
**Checklist:**
1. Verifique arquivo `.env` est√° configurado
2. Confirme conectividade de rede
3. Valide credenciais do banco
4. PostgreSQL Azure requer `sslmode=require`

## üìä Auditoria e Rastreamento

### Hist√≥rico de Execu√ß√µes

Todas as execu√ß√µes do pipeline s√£o registradas automaticamente em `auditoria.historico_execucao`:

```sql
SELECT 
    script_nome,
    usuario_executante,  -- Identifica quem executou (DB_USER)
    data_inicio,
    status,
    linhas_inseridas,
    linhas_erro
FROM auditoria.historico_execucao
ORDER BY data_inicio DESC
LIMIT 20;
```

**Rastreamento autom√°tico:**
- ‚úÖ O sistema usa `DB_USER` do .env para identificar quem executou cada processo
- ‚úÖ Cada pessoa tem seu pr√≥prio usu√°rio no banco, permitindo auditoria completa
- ‚úÖ Todas as m√©tricas (linhas processadas, inseridas, erros) s√£o registradas

## üìä Consultas Anal√≠ticas

Veja [QUERIES.md](QUERIES.md) para exemplos de queries usando `valor_conta` como m√©trica principal:
- Consultas b√°sicas (faturamento por m√™s, top clientes)
- Consultas avan√ßadas com JOINs (performance de vendedores, an√°lise 360¬∞)
- Queries de inadimpl√™ncia e evolu√ß√£o de carteira

## üìö Documenta√ß√£o Adicional

- [QUERIES.md](QUERIES.md) - Exemplos de consultas SQL √∫teis (usando valor_conta)
- [INDEXES.md](INDEXES.md) - Documenta√ß√£o de √≠ndices do banco
- [ACCESS.md](ACCESS.md) - Configura√ß√£o de acesso ao banco

## üéØ Pr√≥ximos Passos

1. **Aplicar √≠ndices de performance** (ver [INDEXES.md](INDEXES.md))
2. **Implementar camada Silver** para transforma√ß√µes
3. **Criar views anal√≠ticas** para relat√≥rios

---

**Vers√£o**: 2.1  
**√öltima Atualiza√ß√£o**: 2025-12-11  
**Mantido por**: Equipe Credits Brasil
