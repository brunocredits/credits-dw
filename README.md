# Credits Brasil Data Warehouse (Credits DW)

Este projeto implementa um pipeline de dados (ETL) containerizado para ingerir dados brutos de arquivos (CSV, Excel, ODS) em um Data Warehouse PostgreSQL na camada Bronze (Raw).

## üìã Vis√£o Geral

O pipeline √© desenvolvido em Python e orquestrado via Docker Compose. Ele suporta:
- **Ingest√£o Din√¢mica:** Detecta automaticamente arquivos de `faturamento`, `base_oficial` e `usuarios` no diret√≥rio de input.
- **Valida√ß√£o de Schema:** Verifica se os arquivos de entrada correspondem aos templates esperados.
- **Limpeza de Dados:** Tratamento b√°sico de tipos num√©ricos e datas.
- **Auditoria Robusta:** Logs de execu√ß√£o e tabela de rejei√ß√£o (`auditoria.log_rejeicao`) detalhada no banco de dados.
- **Estrat√©gia "Warn-on-Fail":** Registros com campos obrigat√≥rios vazios s√£o ingeridos com um aviso (WARN), enquanto erros cr√≠ticos de dados rejeitam o registro (ERROR).

## üèóÔ∏è Estrutura do Projeto

```
credits-dw/
‚îú‚îÄ‚îÄ docker/
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ input/       # Coloque seus arquivos CSV/XLSX aqui
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ processed/   # Arquivos processados s√£o movidos para c√°
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ templates/   # Templates para valida√ß√£o de cabe√ßalho
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îî‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ python/
‚îÇ   ‚îú‚îÄ‚îÄ core/            # L√≥gica base (Ingestor, Validador, Cleaner)
‚îÇ   ‚îú‚îÄ‚îÄ ingestors/       # Classes espec√≠ficas para cada tipo de arquivo
‚îÇ   ‚îú‚îÄ‚îÄ scripts/         # Scripts execut√°veis (run_pipeline.py)
‚îÇ   ‚îî‚îÄ‚îÄ utils/           # Utilit√°rios (DB, Logger)
‚îú‚îÄ‚îÄ logs/                # Logs de execu√ß√£o em arquivo
‚îú‚îÄ‚îÄ QUERIES.md           # Exemplos de consultas SQL
‚îú‚îÄ‚îÄ run_pipeline.sh      # Script facilitador para rodar o ETL
‚îú‚îÄ‚îÄ reset_env.sh         # Script para limpar dados e resetar tabelas
‚îî‚îÄ‚îÄ requirements.txt
```

## üöÄ Como Executar

### Pr√©-requisitos
- Docker e Docker Compose instalados.
- Arquivo `.env` configurado (copie de `.env.example`).

### 1. Configurar Vari√°veis de Ambiente
Crie um arquivo `.env` na raiz do projeto com as credenciais do banco:
```bash
cp .env.example .env
# Edite o .env com suas configura√ß√µes
```

### 2. Colocar Arquivos de Input
Mova os arquivos que deseja processar para `docker/data/input/`.
Exemplo:
```bash
cp meus_dados/*.csv docker/data/input/
```

### 3. Rodar o Pipeline
Execute o script wrapper:
```bash
./run_pipeline.sh
```
Isso ir√°:
1. Buildar a imagem Docker.
2. Executar o processamento.
3. Mover os arquivos processados para `docker/data/processed/YYYY/MM/DD/`.
4. Registrar o resultado no banco de dados.

### 4. Verificar Resultados
Consulte o arquivo [QUERIES.md](QUERIES.md) para exemplos de como explorar os dados ingeridos.

Para verificar erros ou avisos de ingest√£o:
```sql
SELECT * FROM auditoria.log_rejeicao ORDER BY data_hora DESC LIMIT 100;
```

## üõ†Ô∏è Comandos √öteis

- **Resetar Ambiente:** Limpa tabelas bronze e arquivos processados (CUIDADO!).
  ```bash
  ./reset_env.sh
  ```

- **Logs:** Verifique a pasta `logs/` para detalhes t√©cnicos da execu√ß√£o.

## üìù Decis√µes de Arquitetura

- **Camada Bronze (Raw):** O foco √© ingerir os dados com m√≠nima transforma√ß√£o destrutiva.
- **Valida√ß√£o Flex√≠vel:** Campos obrigat√≥rios ausentes geram alertas (`WARN`) mas n√£o bloqueiam a ingest√£o, permitindo corre√ß√£o posterior na camada Silver.
- **Alta Performance:** Uso de `COPY FROM STDIN` do PostgreSQL para carga em massa.

## üîç Campos Obrigat√≥rios por Ingestor

### Faturamento
Apenas 5 campos essenciais:
- `numero_documento`: Identificador √∫nico do documento
- `cnpj`: Cliente (essencial para joins)
- `data_fat`: Data de faturamento 
- `valor_da_conta`: Valor principal
- `empresa`: Empresa emissora (multi-tenant)

> **Nota**: Reduzido de 33 para 5 campos obrigat√≥rios seguindo princ√≠pios da camada Bronze. Valida√ß√µes de neg√≥cio mais rigorosas devem ser feitas na Silver.

### Base Oficial
14 campos refletindo estrutura organizacional:
- `cnpj`, `status`, `manter_no_baseline`
- `razao_social`, `nome_fantasia`
- `canal_1`, `canal_2`
- `lider`, `responsavel`
- `empresa`, `grupo`, `corte`, `segmento`, `obs`

### Usu√°rios
Todos os campos do template s√£o obrigat√≥rios para manter integridade da hierarquia de vendas.

## üöÄ Otimiza√ß√µes de Performance

### √çndices do Banco de Dados

O projeto inclui √≠ndices otimizados para queries anal√≠ticas comuns. Veja o arquivo [INDEXES.md](INDEXES.md) para:
- Lista completa de √≠ndices criados
- Scripts SQL para aplicar
- Instru√ß√µes de monitoramento

**Principais √≠ndices:**
- `bronze.faturamento`: √çndices compostos por empresa+vendedor, cnpj+data
- `bronze.base_oficial`: √çndices por empresa+grupo, canais
- `auditoria.log_rejeicao`: √çndices para debugging (execu√ß√£o, severidade, tabela)

### Estrat√©gia de Valida√ß√£o (WARN vs ERROR)

- **WARN**: Campos obrigat√≥rios vazios ‚Üí Dados s√£o inseridos, mas registrado warning
- **ERROR**: Tipos inv√°lidos (ex: texto em campo num√©rico) ‚Üí Linha rejeitada completamente

Isso permite m√°xima ingest√£o de dados na Bronze, com corre√ß√£o posterior na Silver.

## üîß Troubleshooting

### Problema: Muitos warnings de campos obrigat√≥rios
**Solu√ß√£o**: Revise a qualidade dos dados de origem. Warnings n√£o bloqueiam ingest√£o.

```sql
-- Ver campos mais problem√°ticos
SELECT campo_falha, COUNT(*) as total
FROM auditoria.log_rejeicao
WHERE severidade = 'WARN'
GROUP BY campo_falha
ORDER BY total DESC
LIMIT 10;
```

### Problema: Arquivo n√£o est√° sendo processado
**Causas comuns:**
1. Nome do arquivo n√£o corresponde ao padr√£o esperado
2. Arquivo duplicado (mesmo hash MD5)
3. Headers n√£o correspondem ao template

```sql
-- Ver √∫ltimas execu√ß√µes com erro
SELECT script_nome, tabela_destino, mensagem_erro, data_inicio
FROM auditoria.historico_execucao
WHERE status = 'erro'
ORDER BY data_inicio DESC
LIMIT 5;
```

### Problema: Performance lenta
**Solu√ß√µes:**
1. Verifique se √≠ndices foram criados (veja INDEXES.md)
2. Execute `VACUUM ANALYZE` ap√≥s grandes cargas
3. Considere aumentar `work_mem` do PostgreSQL para sorts grandes

```sql
-- Verificar tamanho das tabelas
SELECT 
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size
FROM pg_tables
WHERE schemaname IN ('bronze', 'auditoria')
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;
```

### Problema: Erro de conex√£o com o banco
**Checklist:**
1. Verifique arquivo `.env` est√° configurado
2. Confirme conectividade de rede
3. Valide credenciais do banco
4. PostgreSQL Azure requer `sslmode=require`

## üìö Documenta√ß√£o Adicional

- [QUERIES.md](QUERIES.md) - Exemplos de consultas SQL √∫teis
- [INDEXES.md](INDEXES.md) - Documenta√ß√£o de √≠ndices do banco
- [ACCESS.md](ACCESS.md) - Configura√ß√£o de acesso ao banco

## üîê Permiss√µes do Banco de Dados

### Usu√°rios Configurados

Todos os usu√°rios abaixo t√™m permiss√µes completas nas tabelas bronze e auditoria:

- `bruno.pires@creditsbrasil.com.br`
- `bruno_cavalcante`
- `crislaine_cardoso`
- `joao.viveiros@creditsbrasil.com.br`
- `joao_viveiros`
- `maria.rodrigues@creditsbrasil.com.br`
- `maria_rodrigues`

### Privil√©gios Concedidos

Cada usu√°rio pode:
- ‚úÖ `SELECT` - Consultar dados
- ‚úÖ `INSERT` - Inserir registros
- ‚úÖ `UPDATE` - Atualizar registros
- ‚úÖ `DELETE` - Deletar registros
- ‚úÖ `TRUNCATE` - Limpar tabelas (necess√°rio para reset)
- ‚úÖ Executar todos os scripts do projeto

## üìà √öltimas Otimiza√ß√µes Aplicadas

### C√≥digo
- ‚úÖ Coment√°rios inline explicativos em se√ß√µes cr√≠ticas
- ‚úÖ Redu√ß√£o de campos obrigat√≥rios (faturamento: 33‚Üí5)
- ‚úÖ Documenta√ß√£o de contexto de neg√≥cio
- ‚úÖ Valida√ß√µes alinhadas com princ√≠pios Bronze Layer

### Performance
- ‚úÖ 11 novos √≠ndices documentados (ver INDEXES.md)
- ‚úÖ Queries anal√≠ticas otimizadas
- ‚úÖ COPY FROM STDIN para bulk inserts

### Qualidade de Dados
- ‚úÖ Estrat√©gia WARN vs ERROR implementada
- ‚úÖ Sistema de auditoria completo
- ‚úÖ Detec√ß√£o de duplicatas por hash MD5
- ‚úÖ 91.2% taxa de sucesso na √∫ltima ingest√£o

## üéØ Pr√≥ximos Passos

1. **Aplicar √≠ndices de performance** (ver [INDEXES.md](INDEXES.md))
2. **Implementar camada Silver** para transforma√ß√µes
3. **Corrigir datas inv√°lidas** no arquivo fonte de faturamento
4. **Criar views anal√≠ticas** para relat√≥rios

---

**Vers√£o**: 2.0  
**√öltima Atualiza√ß√£o**: 2025-12-09  
**Mantido por**: Equipe Credits Brasil
