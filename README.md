# üè¶ Data Warehouse Credits Brasil

> **Vers√£o 3.0** | **Arquitetura Bronze Layer** | **PostgreSQL 15** | **Python 3.10+**

---

## üìã √çndice

1. [Vis√£o Geral](#-vis√£o-geral)
2. [Arquitetura](#-arquitetura)
3. [Pr√©-requisitos](#-pr√©-requisitos)
4. [Instala√ß√£o](#-instala√ß√£o)
5. [Configura√ß√£o](#-configura√ß√£o)
6. [Uso](#-uso)
7. [Estrutura do Projeto](#-estrutura-do-projeto)
8. [Desenvolvimento](#-desenvolvimento)
9. [Melhorias da Vers√£o 3.0](#-melhorias-da-vers√£o-30)
10. [Troubleshooting](#-troubleshooting)
11. [Contribui√ß√£o](#-contribui√ß√£o)

---

## üéØ Vis√£o Geral

Data Warehouse moderno para consolida√ß√£o de dados financeiros e operacionais da Credits Brasil. O projeto implementa um **pipeline ETL robusto** que processa arquivos CSV e os carrega em uma camada Bronze no PostgreSQL, seguindo as melhores pr√°ticas de engenharia de dados.

### ‚ú® Caracter√≠sticas Principais

- **üèóÔ∏è Camada Bronze**: Armazena dados brutos com m√≠nima transforma√ß√£o
- **üîÑ ETL Automatizado**: Scripts Python modulares e reutiliz√°veis
- **üê≥ Containerizado**: Ambiente Docker para consist√™ncia entre dev/prod
- **üìä Auditoria Completa**: Rastreamento de todas as execu√ß√µes no schema `credits`
- **‚ö° Performance**: Inser√ß√µes em batch com retry autom√°tico
- **üîç Observabilidade**: Logs estruturados com Loguru e m√©tricas detalhadas
- **üöÄ Paraleliza√ß√£o**: Suporte a execu√ß√£o paralela de m√∫ltiplos ingestores
- **üõ°Ô∏è Seguran√ßa**: Credenciais em vari√°veis de ambiente, sem hardcoding

---

## üèóÔ∏è Arquitetura

### Fluxo de Dados

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Arquivos CSV   ‚îÇ  (OneDrive, SFTP, etc)
‚îÇ  - Faturamento  ‚îÇ
‚îÇ  - Usu√°rios     ‚îÇ
‚îÇ  - Contas       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ETL Processor  ‚îÇ  (Python + Pandas)
‚îÇ  - Valida√ß√£o    ‚îÇ
‚îÇ  - Limpeza      ‚îÇ
‚îÇ  - Formata√ß√£o   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ PostgreSQL      ‚îÇ
‚îÇ ‚îú‚îÄ‚îÄ bronze.*    ‚îÇ  (Dados Brutos)
‚îÇ ‚îî‚îÄ‚îÄ credits.*   ‚îÇ  (Metadados & Auditoria)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Schemas do Banco de Dados

#### `bronze` - Dados Brutos
Cont√©m as tabelas com dados originais das fontes CSV:

| Tabela                    | Descri√ß√£o                          | Atualiza√ß√£o |
|---------------------------|------------------------------------|-------------|
| `bronze.faturamento`      | Receitas di√°rias por data          | Di√°ria      |
| `bronze.usuarios`         | Cadastro de usu√°rios e hierarquia  | Di√°ria      |
| `bronze.contas_base_oficial` | Contas de clientes (B2B)      | Di√°ria      |
| `bronze.data`             | Dimens√£o de data pr√©-calculada     | Uma vez     |

#### `credits` - Metadados e Auditoria
Sistema de controle e observabilidade:

| Tabela                         | Descri√ß√£o                                    |
|--------------------------------|----------------------------------------------|
| `credits.historico_atualizacoes` | Log de execu√ß√µes ETL com m√©tricas e status |

### A Dimens√£o de Data

A tabela `bronze.data` √© uma **Date Dimension Table**, t√©cnica essencial em Data Warehousing:

**Benef√≠cios:**
- ‚ö° **Performance**: Agrega√ß√µes 10x mais r√°pidas (ex: `GROUP BY trimestre`)
- üß© **Simplicidade**: SQL mais limpo, sem fun√ß√µes complexas de data
- üìè **Consist√™ncia**: Todos usam as mesmas defini√ß√µes de per√≠odos
- üîÑ **Reusabilidade**: Uma vez criada, serve para todas as an√°lises

**Exemplo de uso:**
```sql
-- Receita por trimestre (r√°pido e simples)
SELECT d.trimestre, SUM(f.receita::numeric)
FROM bronze.faturamento f
JOIN bronze.data d ON f.data = d.data_completa
GROUP BY d.trimestre
ORDER BY d.trimestre;
```

---

## üíª Pr√©-requisitos

### Requisitos M√≠nimos

- **Docker** 20.10+ e **Docker Compose** V2
- **Python** 3.10+ (para desenvolvimento local)
- **PostgreSQL** 15+ (gerenciado externamente)
- **Cliente PostgreSQL** (DBeaver, pgAdmin, psql, etc.)
- **Git** para controle de vers√£o

### Requisitos Recomendados

- 2 CPU cores / 2GB RAM para container ETL
- 10GB de espa√ßo em disco para logs e arquivos processados
- Conex√£o de rede est√°vel com o banco PostgreSQL

---

## üöÄ Instala√ß√£o

### 1. Clonar Reposit√≥rio

```bash
git clone https://github.com/brunocredits/credits-dw.git
cd credits-dw
```

### 2. Configurar Vari√°veis de Ambiente

Copie o template e preencha com suas credenciais:

```bash
cp .env.example .env
```

Edite o arquivo `.env`:

```properties
# Conex√£o PostgreSQL
DB_HOST=seu_host.postgres.database.azure.com
DB_PORT=5432
DB_NAME=creditsdw
DB_USER=seu_usuario
DB_PASSWORD=sua_senha_forte

# Configura√ß√µes Opcionais
LOG_LEVEL=INFO                    # DEBUG, INFO, WARNING, ERROR
ETL_BATCH_SIZE=1000              # Tamanho do batch para inser√ß√µes
ETL_PARALLEL_INGESTORS=3         # N√∫mero de ingestores em paralelo
CSV_SEPARATOR=;                  # Separador dos CSVs
CSV_ENCODING=utf-8-sig           # Encoding dos CSVs
```

**‚ö†Ô∏è IMPORTANTE**: Nunca commite o arquivo `.env` no Git!

### 3. Preparar Dados de Entrada

Coloque seus arquivos CSV no diret√≥rio de input:

```bash
# Estrutura esperada
docker/data/input/onedrive/
‚îú‚îÄ‚îÄ faturamento.csv
‚îú‚îÄ‚îÄ usuarios.csv
‚îî‚îÄ‚îÄ contas_base_oficial.csv
```

**Templates de exemplo:**
```bash
# Para testar, copie os templates
cp docker/data/templates/*.csv docker/data/input/onedrive/
```

### 4. Iniciar Container ETL

```bash
cd docker
docker compose up -d --build
```

Verificar se est√° rodando:
```bash
docker compose ps
# Deve mostrar: credits-dw-etl com status "Up"
```

---

## ‚öôÔ∏è Configura√ß√£o

### Configura√ß√£o Centralizada

A vers√£o 3.0 introduz configura√ß√£o centralizada em `python/utils/config.py`:

```python
from utils.config import get_config

config = get_config()
print(f"Database: {config.database.host}")
print(f"Batch size: {config.etl.batch_insert_size}")
```

### Vari√°veis de Ambiente Dispon√≠veis

| Vari√°vel | Padr√£o | Descri√ß√£o |
|----------|--------|-----------|
| `DB_HOST` | - | **Obrigat√≥rio**. Host do PostgreSQL |
| `DB_PORT` | 5432 | Porta do PostgreSQL |
| `DB_NAME` | - | **Obrigat√≥rio**. Nome do banco de dados |
| `DB_USER` | - | **Obrigat√≥rio**. Usu√°rio do banco |
| `DB_PASSWORD` | - | **Obrigat√≥rio**. Senha do banco |
| `LOG_LEVEL` | INFO | N√≠vel de log (DEBUG/INFO/WARNING/ERROR) |
| `ETL_MAX_RETRIES` | 3 | Tentativas em caso de falha |
| `ETL_BATCH_SIZE` | 1000 | Registros por batch |
| `ETL_PARALLEL_INGESTORS` | 1 | Ingestores em paralelo |
| `CSV_SEPARATOR` | ; | Separador de colunas CSV |
| `CSV_ENCODING` | utf-8-sig | Encoding dos arquivos CSV |

---

## üéÆ Uso

### Comandos Essenciais

#### Executar TODOS os Ingestores

```bash
# Modo sequencial (padr√£o)
docker compose exec etl-processor python python/run_all_ingestors.py

# Modo paralelo (mais r√°pido)
docker compose exec etl-processor python python/run_all_ingestors.py --parallel

# Especificar n√∫mero de workers
docker compose exec etl-processor python python/run_all_ingestors.py --parallel --workers 5
```

#### Executar Ingestores Espec√≠ficos

```bash
# Apenas faturamento e usu√°rios
docker compose exec etl-processor python python/run_all_ingestors.py \
  --scripts faturamento usuarios

# Listar ingestores dispon√≠veis
docker compose exec etl-processor python python/run_all_ingestors.py --list
```

#### Executar Ingestor Individual

```bash
# Faturamento
docker compose exec etl-processor python python/ingestors/csv/ingest_faturamento.py

# Usu√°rios
docker compose exec etl-processor python python/ingestors/csv/ingest_usuarios.py

# Contas
docker compose exec etl-processor python python/ingestors/csv/ingest_contas_base_oficial.py
```

### Acessar Shell do Container

```bash
docker compose exec etl-processor bash
```

### Visualizar Logs

```bash
# Logs do container
docker compose logs -f etl-processor

# Logs dos scripts (dentro do container)
docker compose exec etl-processor tail -f /app/logs/*.log
```

### Parar e Remover Container

```bash
docker compose down
```

### Reconstruir Container (ap√≥s mudan√ßas)

```bash
docker compose up -d --build
```

---

## üìÇ Estrutura do Projeto

```
credits-dw/
‚îú‚îÄ‚îÄ üìÅ docker/                          # Configura√ß√£o Docker
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile                      # Imagem Python ETL
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yml              # Orquestra√ß√£o de servi√ßos
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ data/
‚îÇ       ‚îú‚îÄ‚îÄ üìÅ input/onedrive/          # CSVs a processar
‚îÇ       ‚îú‚îÄ‚îÄ üìÅ processed/               # CSVs j√° processados (backup)
‚îÇ       ‚îî‚îÄ‚îÄ üìÅ templates/               # Exemplos de CSV
‚îÇ
‚îú‚îÄ‚îÄ üìÅ python/                          # C√≥digo-fonte Python
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ ingestors/                   # Scripts de ingest√£o
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ üìÅ csv/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ base_csv_ingestor.py    # ‚≠ê Classe base (Template Method)
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ ingest_faturamento.py   # Ingestor de faturamento
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ ingest_usuarios.py      # Ingestor de usu√°rios
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ ingest_contas_base_oficial.py  # Ingestor de contas
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ utils/                       # Utilit√°rios compartilhados
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py                   # ‚≠ê Configura√ß√£o centralizada
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ db_connection.py            # ‚≠ê Gerenciamento de conex√µes
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ audit.py                    # ‚≠ê Sistema de auditoria
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ logger.py                   # ‚≠ê Logging com Loguru
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ run_all_ingestors.py            # ‚≠ê Orquestrador principal
‚îÇ
‚îú‚îÄ‚îÄ üìÅ docs/                            # Documenta√ß√£o adicional
‚îÇ   ‚îú‚îÄ‚îÄ 01-Configuracao-Ambiente.md
‚îÇ   ‚îú‚îÄ‚îÄ 02-Acesso-Banco-de-Dados.md
‚îÇ   ‚îú‚îÄ‚îÄ 03-Executando-ETL.md
‚îÇ   ‚îî‚îÄ‚îÄ 04-Estrutura-Projeto.md
‚îÇ
‚îú‚îÄ‚îÄ .env.example                        # Template de vari√°veis de ambiente
‚îú‚îÄ‚îÄ .gitignore                          # Arquivos ignorados pelo Git
‚îú‚îÄ‚îÄ requirements.txt                    # Depend√™ncias Python
‚îú‚îÄ‚îÄ README.md                           # üìñ Esta documenta√ß√£o
‚îî‚îÄ‚îÄ CLAUDE.md                           # Guia para Claude Code

‚≠ê = Arquivos principais/refatorados na v3.0
```

### Arquivos Principais

| Arquivo | Descri√ß√£o | Vers√£o |
|---------|-----------|--------|
| `base_csv_ingestor.py` | Classe base abstrata com Template Method pattern | v3.0 |
| `config.py` | Configura√ß√£o centralizada com dataclasses | v3.0 |
| `db_connection.py` | Context managers e retry logic para PostgreSQL | v3.0 |
| `audit.py` | Sistema de auditoria com context managers | v3.0 |
| `logger.py` | Logging estruturado com Loguru e rota√ß√£o | v3.0 |
| `run_all_ingestors.py` | Orquestrador com paraleliza√ß√£o e CLI | v3.0 |

---

## üõ†Ô∏è Desenvolvimento

### Setup Local (Sem Docker)

```bash
# Criar ambiente virtual
python3.10 -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows

# Instalar depend√™ncias
pip install -r requirements.txt

# Executar ingestor
python python/ingestors/csv/ingest_faturamento.py
```

### Criar Novo Ingestor

1. **Herdar da classe base:**

```python
# python/ingestors/csv/ingest_meu_dados.py
from ingestors.csv.base_csv_ingestor import BaseCSVIngestor
from typing import Dict, List

class IngestMeusDados(BaseCSVIngestor):
    def __init__(self):
        super().__init__(
            script_name='ingest_meus_dados.py',
            tabela_destino='bronze.meus_dados',
            arquivo_nome='meus_dados.csv',
            input_subdir='onedrive'
        )

    def get_column_mapping(self) -> Dict[str, str]:
        """Mapeia colunas CSV -> Bronze"""
        return {
            'Coluna CSV': 'coluna_bronze',
            'Outra Coluna': 'outra_coluna'
        }

    def get_bronze_columns(self) -> List[str]:
        """Lista colunas Bronze na ordem"""
        return ['coluna_bronze', 'outra_coluna']

if __name__ == '__main__':
    import sys
    sys.exit(IngestMeusDados().executar())
```

2. **Registrar no orquestrador:**

```python
# python/run_all_ingestors.py
from ingestors.csv.ingest_meus_dados import IngestMeusDados

INGESTORS_REGISTRY = {
    'contas': IngestContasBaseOficial,
    'faturamento': IngestFaturamento,
    'usuarios': IngestUsuarios,
    'meus_dados': IngestMeusDados,  # ‚Üê Adicionar aqui
}
```

3. **Criar tabela no PostgreSQL:**

```sql
CREATE TABLE bronze.meus_dados (
    coluna_bronze TEXT,
    outra_coluna TEXT,
    data_carga_bronze TIMESTAMP DEFAULT NOW()
);
```

### Ferramentas de Qualidade de C√≥digo

```bash
# Formata√ß√£o autom√°tica
black python/

# Linting
ruff check python/

# Type checking
mypy python/

# Executar todos
black python/ && ruff check python/ && mypy python/
```

### Testes (Futuro)

```bash
# Executar testes unit√°rios
pytest python/tests/ -v

# Com cobertura
pytest python/tests/ --cov=python --cov-report=html
```

---

## üéâ Melhorias da Vers√£o 3.0

### üÜï Novos Recursos

#### 1. **Configura√ß√£o Centralizada** (`config.py`)
- ‚úÖ Dataclasses para configura√ß√£o tipada
- ‚úÖ Valida√ß√£o autom√°tica de vari√°veis obrigat√≥rias
- ‚úÖ Singleton pattern para configura√ß√£o global
- ‚úÖ Suporte a m√∫ltiplos ambientes

#### 2. **Logging Aprimorado** (`logger.py`)
- ‚úÖ Migra√ß√£o para Loguru (logs mais bonitos e informativos)
- ‚úÖ Rota√ß√£o autom√°tica de logs (100MB, 30 dias)
- ‚úÖ Compress√£o de logs antigos em ZIP
- ‚úÖ Formata√ß√£o colorida no console
- ‚úÖ M√©tricas de throughput (linhas/segundo)

#### 3. **Conex√µes Robustas** (`db_connection.py`)
- ‚úÖ Context managers (`with get_connection()`)
- ‚úÖ Retry autom√°tico em falhas de conex√£o (tenacity)
- ‚úÖ Pool de conex√µes configur√°vel
- ‚úÖ Cursores especializados (dict cursor)
- ‚úÖ Health check de conex√£o

#### 4. **Auditoria Avan√ßada** (`audit.py`)
- ‚úÖ Context manager para auditoria autom√°tica
- ‚úÖ Estat√≠sticas de execu√ß√£o (taxa de sucesso, dura√ß√£o m√©dia)
- ‚úÖ Consulta de execu√ß√µes em andamento
- ‚úÖ Hist√≥rico detalhado por script

#### 5. **ETL Otimizado** (`base_csv_ingestor.py`)
- ‚úÖ Valida√ß√£o de arquivo e schema
- ‚úÖ Inser√ß√µes em batch configur√°veis
- ‚úÖ M√©tricas de performance (tempo, throughput)
- ‚úÖ Logs estruturados e informativos
- ‚úÖ Tratamento robusto de erros

#### 6. **Orquestra√ß√£o Avan√ßada** (`run_all_ingestors.py`)
- ‚úÖ **Execu√ß√£o paralela** de ingestores
- ‚úÖ CLI completo com argparse
- ‚úÖ Relat√≥rio consolidado de execu√ß√£o
- ‚úÖ Execu√ß√£o seletiva de ingestores
- ‚úÖ Listagem de ingestores dispon√≠veis

### üîß Melhorias T√©cnicas

| √Årea | v2.0 | v3.0 |
|------|------|------|
| **Logging** | logging padr√£o | Loguru com rota√ß√£o |
| **Config** | Hardcoded/env vars | Centralizado com valida√ß√£o |
| **Conex√µes** | Manual | Context managers + retry |
| **Auditoria** | B√°sica | Avan√ßada com m√©tricas |
| **Paraleliza√ß√£o** | ‚ùå | ‚úÖ ThreadPoolExecutor |
| **CLI** | ‚ùå | ‚úÖ argparse completo |
| **Valida√ß√£o** | M√≠nima | Schema + arquivo + dados |
| **M√©tricas** | B√°sicas | Throughput + dura√ß√£o detalhada |
| **Seguran√ßa** | Senhas hardcoded | 100% env vars + valida√ß√£o |

---

## üêõ Troubleshooting

### Problema: Container n√£o inicia

```bash
# Ver logs detalhados
docker compose logs etl-processor

# Reconstruir imagem
docker compose down
docker compose build --no-cache
docker compose up -d
```

### Problema: Erro de conex√£o com banco de dados

```bash
# Testar conex√£o manualmente
docker compose exec etl-processor psql -h $DB_HOST -U $DB_USER -d $DB_NAME

# Verificar vari√°veis de ambiente
docker compose exec etl-processor env | grep DB_
```

**Solu√ß√µes comuns:**
- ‚úÖ Verifique se `.env` est√° configurado corretamente
- ‚úÖ Confirme que o IP do container tem acesso ao PostgreSQL
- ‚úÖ Verifique firewall/security groups no Azure
- ‚úÖ Teste credenciais com cliente PostgreSQL local

### Problema: Arquivo CSV n√£o encontrado

```bash
# Listar arquivos no container
docker compose exec etl-processor ls -la /app/data/input/onedrive/

# Copiar arquivo para container
docker cp meu_arquivo.csv credits-dw-etl:/app/data/input/onedrive/
```

### Problema: Erro "Missing required environment variables"

**Causa:** Vari√°veis obrigat√≥rias n√£o definidas no `.env`

**Solu√ß√£o:**
```bash
# Verificar .env existe
ls -la .env

# Comparar com template
diff .env .env.example

# Garantir que Docker Compose carrega .env
docker compose config | grep DB_HOST
```

### Problema: Logs n√£o aparecem

```bash
# Verificar permiss√µes
docker compose exec etl-processor ls -la /app/logs/

# Criar diret√≥rio manualmente
docker compose exec etl-processor mkdir -p /app/logs
docker compose exec etl-processor chmod 777 /app/logs
```

### Problema: Performance lenta

**Otimiza√ß√µes:**

1. **Aumentar batch size:**
```bash
# No .env
ETL_BATCH_SIZE=5000  # Padr√£o: 1000
```

2. **Usar execu√ß√£o paralela:**
```bash
docker compose exec etl-processor python python/run_all_ingestors.py \
  --parallel --workers 5
```

3. **Ajustar resources no Docker:**
```yaml
# docker-compose.yml
deploy:
  resources:
    limits:
      cpus: "4"      # Aumentar CPUs
      memory: 4G     # Aumentar RAM
```

---

## üìä Monitoramento e Observabilidade

### Consultar Hist√≥rico de Execu√ß√µes

```sql
-- √öltimas 10 execu√ß√µes
SELECT
    script_nome,
    status,
    data_inicio,
    data_fim,
    EXTRACT(EPOCH FROM (data_fim - data_inicio)) as duracao_segundos,
    linhas_processadas,
    linhas_inseridas
FROM credits.historico_atualizacoes
ORDER BY data_inicio DESC
LIMIT 10;

-- Taxa de sucesso por script (√∫ltimos 30 dias)
SELECT
    script_nome,
    COUNT(*) as total_execucoes,
    SUM(CASE WHEN status = 'sucesso' THEN 1 ELSE 0 END) as sucessos,
    ROUND(SUM(CASE WHEN status = 'sucesso' THEN 1 ELSE 0 END)::numeric / COUNT(*) * 100, 2) as taxa_sucesso
FROM credits.historico_atualizacoes
WHERE data_inicio >= NOW() - INTERVAL '30 days'
GROUP BY script_nome
ORDER BY taxa_sucesso DESC;

-- Execu√ß√µes em andamento (poss√≠vel travamento)
SELECT
    script_nome,
    data_inicio,
    NOW() - data_inicio as tempo_decorrido
FROM credits.historico_atualizacoes
WHERE status = 'em_execucao'
  AND data_inicio < NOW() - INTERVAL '1 hour';  -- Mais de 1h rodando
```

### M√©tricas de Performance

Os logs agora incluem:
- ‚è±Ô∏è Dura√ß√£o total da execu√ß√£o
- üìà Throughput (linhas/segundo)
- üíæ Uso de mem√≥ria do DataFrame
- üìä Estat√≠sticas de valores nulos
- üî¢ Contadores de linhas processadas vs inseridas

---

## ü§ù Contribui√ß√£o

### Fluxo de Trabalho

1. **Fork** o reposit√≥rio
2. **Clone** seu fork localmente
3. **Crie branch** para sua feature (`git checkout -b feat/nova-feature`)
4. **Commit** suas mudan√ßas (`git commit -m 'feat: adiciona nova feature'`)
5. **Push** para o branch (`git push origin feat/nova-feature`)
6. **Abra Pull Request** no GitHub

### Conven√ß√µes de Commit

Seguimos [Conventional Commits](https://www.conventionalcommits.org/):

- `feat:` Nova funcionalidade
- `fix:` Corre√ß√£o de bug
- `refactor:` Refatora√ß√£o sem mudan√ßa de funcionalidade
- `docs:` Mudan√ßas na documenta√ß√£o
- `test:` Adi√ß√£o ou corre√ß√£o de testes
- `chore:` Tarefas de manuten√ß√£o

---

## üìù Licen√ßa

Este projeto √© de propriedade da **Credits Brasil** e √© de uso interno.

---

## üë• Equipe

**Mantido por:** Equipe de Engenharia de Dados - Credits Brasil

**Contato:** [Seu email/Slack aqui]

---

## üìö Documenta√ß√£o Adicional

Para mais detalhes, consulte:

- üìÑ [CLAUDE.md](./CLAUDE.md) - Guia para Claude Code
- üìÑ [docs/01-Configuracao-Ambiente.md](./docs/01-Configuracao-Ambiente.md)
- üìÑ [docs/02-Acesso-Banco-de-Dados.md](./docs/02-Acesso-Banco-de-Dados.md)
- üìÑ [docs/03-Executando-ETL.md](./docs/03-Executando-ETL.md)
- üìÑ [docs/04-Estrutura-Projeto.md](./docs/04-Estrutura-Projeto.md)

---

<div align="center">

**üöÄ Feito com ‚ù§Ô∏è pela equipe de Engenharia de Dados da Credits Brasil**

‚≠ê Se este projeto foi √∫til, considere dar uma estrela!

</div>
