# Credits DW - Data Warehouse Pipeline

Pipeline de ingestÃ£o de dados para a camada Bronze do Data Warehouse, implementado com arquitetura modular e otimizado para alta performance.

## ğŸ—ï¸ Arquitetura

### Camadas do Data Warehouse
- **Bronze (RAW)**: Dados brutos validados e limpos
- **Silver**: Dados transformados e enriquecidos *(prÃ³xima etapa)*
- **Gold**: Dados agregados para consumo *(prÃ³xima etapa)*

### Componentes Principais

```
python/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ base_ingestor.py    # Orquestrador principal
â”‚   â”œâ”€â”€ data_cleaner.py     # Limpeza de dados
â”‚   â”œâ”€â”€ file_handler.py     # Gerenciamento de arquivos
â”‚   â””â”€â”€ validator.py        # ValidaÃ§Ã£o de estrutura
â”œâ”€â”€ ingestors/
â”‚   â”œâ”€â”€ ingest_faturamento.py
â”‚   â”œâ”€â”€ ingest_usuarios.py
â”‚   â””â”€â”€ ingest_base_oficial.py
â””â”€â”€ utils/
    â”œâ”€â”€ db_connection.py    # ConexÃ£o com PostgreSQL
    â””â”€â”€ audit.py            # Sistema de auditoria
```

## ğŸš€ Quick Start

### PrÃ©-requisitos
- Docker e Docker Compose
- PostgreSQL (Azure Database for PostgreSQL)
- Python 3.9+

### ConfiguraÃ§Ã£o

1. **Clone o repositÃ³rio**
```bash
git clone https://github.com/brunocredits/credits-dw.git
cd credits-dw
```

2. **Configure variÃ¡veis de ambiente**
```bash
cp .env.example .env
# Edite .env com suas credenciais
```

3. **Execute o pipeline**
```bash
./run_pipeline.sh
```

### Reset do Ambiente
Para limpar dados e preparar nova carga:
```bash
./reset_env.sh
```

## ğŸ“Š Funcionalidades

### âœ… Implementado

- **DetecÃ§Ã£o de Duplicatas**: Hash MD5 para evitar reprocessamento
- **ValidaÃ§Ã£o de Headers**: ComparaÃ§Ã£o com templates oficiais
- **Limpeza de Dados**:
  - ConversÃ£o de formato brasileiro (1.000,00 â†’ 1000.00)
  - Tratamento de hÃ­fen como zero
  - ValidaÃ§Ã£o de datas (DD/MM/YYYY)
- **IdempotÃªncia**: Delete-before-load por arquivo
- **Auditoria Completa**: Rastreamento de execuÃ§Ãµes e erros
- **Alta Performance**: PostgreSQL COPY para carga em massa

### ğŸ¯ CaracterÃ­sticas TÃ©cnicas

- **Arquitetura Modular**: PrincÃ­pios SOLID (SRP, DIP)
- **Clean Code**: CÃ³digo documentado em portuguÃªs
- **SeguranÃ§a**: ValidaÃ§Ã£o rigorosa, parÃ¢metros bind SQL
- **Performance**: OperaÃ§Ãµes vetorizadas (Pandas/Numpy)

## ğŸ“ Estrutura de Dados

### Tabelas Bronze
- `bronze.faturamento` - Dados de faturamento (32 colunas)
- `bronze.usuarios` - Cadastro de usuÃ¡rios
- `bronze.base_oficial` - Base oficial de clientes
- `bronze.data` - Tabela de datas (dimensÃ£o)

### Auditoria
- `auditoria.historico_execucao` - Log de execuÃ§Ãµes
- `auditoria.log_rejeicao` - Linhas rejeitadas com motivo

## ğŸ” Queries de Monitoramento

### Verificar Ãºltima execuÃ§Ã£o
```sql
SELECT script_nome, data_inicio, status, 
       linhas_processadas, linhas_inseridas, linhas_erro
FROM auditoria.historico_execucao
ORDER BY data_inicio DESC
LIMIT 10;
```

### Analisar rejeiÃ§Ãµes
```sql
SELECT tabela_destino, motivo_rejeicao, COUNT(*) as qtd
FROM auditoria.log_rejeicao
GROUP BY tabela_destino, motivo_rejeicao
ORDER BY qtd DESC;
```

### Verificar duplicatas detectadas
```sql
SELECT COUNT(*) as arquivos_duplicados
FROM auditoria.historico_execucao
WHERE status = 'sucesso' 
  AND file_hash IN (
    SELECT file_hash 
    FROM auditoria.historico_execucao 
    GROUP BY file_hash 
    HAVING COUNT(*) > 1
  );
```

## ğŸ“‹ PrÃ³ximos Passos

### ğŸ”„ Camada Silver (TransformaÃ§Ã£o)
- [ ] Criar mÃ³dulo de transformaÃ§Ã£o de dados
- [ ] Implementar deduplicaÃ§Ã£o de registros
- [ ] Adicionar enriquecimento de dados
- [ ] Criar tabelas de dimensÃ£o (SCD Type 2)
- [ ] Implementar validaÃ§Ãµes de negÃ³cio avanÃ§adas

### ğŸ“Š Camada Gold (AgregaÃ§Ã£o)
- [ ] Criar views materializadas para dashboards
- [ ] Implementar mÃ©tricas de negÃ³cio
- [ ] Adicionar tabelas de fatos agregadas
- [ ] Otimizar para queries analÃ­ticas

### ğŸ”§ Melhorias TÃ©cnicas
- [ ] Implementar testes unitÃ¡rios (pytest)
- [ ] Adicionar testes de integraÃ§Ã£o
- [ ] Configurar CI/CD (GitHub Actions)
- [ ] Implementar monitoramento com Prometheus/Grafana
- [ ] Adicionar alertas automÃ¡ticos (Slack/Email)
- [ ] Criar documentaÃ§Ã£o tÃ©cnica completa (Sphinx)

### ğŸš€ Performance
- [ ] Implementar particionamento de tabelas
- [ ] Adicionar Ã­ndices otimizados
- [ ] Configurar vacuum automÃ¡tico
- [ ] Implementar cache de queries frequentes

### ğŸ” SeguranÃ§a
- [ ] Implementar criptografia de dados sensÃ­veis
- [ ] Adicionar auditoria de acessos
- [ ] Configurar backup automÃ¡tico
- [ ] Implementar disaster recovery

### ğŸ“± Observabilidade
- [ ] Dashboard de mÃ©tricas em tempo real
- [ ] Logs centralizados (ELK Stack)
- [ ] Rastreamento distribuÃ­do (OpenTelemetry)
- [ ] SLA monitoring

## ğŸ› ï¸ Desenvolvimento

### Estrutura de Branches
- `main` - ProduÃ§Ã£o
- `develop` - Desenvolvimento
- `feature/*` - Novas funcionalidades
- `hotfix/*` - CorreÃ§Ãµes urgentes

### PadrÃµes de Commit
```
feat: Nova funcionalidade
fix: CorreÃ§Ã£o de bug
docs: DocumentaÃ§Ã£o
refactor: RefatoraÃ§Ã£o
perf: Melhoria de performance
test: Testes
chore: Tarefas gerais
```

## ğŸ“š DocumentaÃ§Ã£o Adicional

- [Guia de DemonstraÃ§Ã£o](/.gemini/antigravity/brain/.../DEMO_GUIDE.md)
- [Regras de ValidaÃ§Ã£o](/.gemini/antigravity/brain/.../regras_validacao_faturamento.md)
- [Estrutura do Banco](/.gemini/antigravity/brain/.../estrutura_banco_dados.md)

## ğŸ¤ Contribuindo

1. Fork o projeto
2. Crie uma branch (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'feat: Add AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“ LicenÃ§a

Projeto proprietÃ¡rio - Credits Brasil

## ğŸ‘¥ Time

- **Desenvolvedor**: Bruno Pires
- **OrganizaÃ§Ã£o**: Credits Brasil

---

**Status**: âœ… Bronze Layer - ProduÃ§Ã£o  
**PrÃ³xima Milestone**: ğŸ”„ Silver Layer - Em Planejamento